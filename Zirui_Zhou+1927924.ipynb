{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading\n",
    "\n",
    "\n",
    "class QueueThread(threading.Thread):\n",
    "    \"\"\"A simple class to support tasks for queue in thread.\n",
    "\n",
    "    Attributes:\n",
    "        func: A function for the target task.\n",
    "        queue: A queue.Queue object to acquire params for the function.\n",
    "    \"\"\"\n",
    "    def __init__(self, func, queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.queue = queue\n",
    "        self.daemon = True\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Start function.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Exit the thread if there is no item in the queue.\n",
    "            try:\n",
    "                self.func(*self.queue.get_nowait())\n",
    "            except queue.Empty:\n",
    "                return\n",
    "            self.queue.task_done()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "class CommonRequest():\n",
    "    \"\"\"A simple class to support basic requests.\n",
    "\n",
    "    Attributes:\n",
    "        retry_c: A list of HTTP status codes for retrying.\n",
    "        retry_e: A tuple of Exceptions for retrying.\n",
    "        retry_interval: A integer of the interval (second) between two retry requests.\n",
    "    \"\"\"\n",
    "    retry_c = [\n",
    "        requests.codes.too_many_requests,\n",
    "    ]\n",
    "    retry_e = (\n",
    "        requests.exceptions.ConnectionError,\n",
    "        # For Exceptions raised from `retry_c`.\n",
    "        requests.exceptions.HTTPError,\n",
    "        requests.exceptions.Timeout,\n",
    "    )\n",
    "    retry_interval = 1\n",
    "\n",
    "    @classmethod\n",
    "    def common_get(cls, url, params=None, timeout=5, logger=None):\n",
    "        \"\"\"A function for common get request.\n",
    "\n",
    "        Args:\n",
    "            url: A string of the request url.\n",
    "            params: A dictionary of the params.\n",
    "            timeout: A integer of the timeout (seconds).\n",
    "            logger: A logger object for logging.\n",
    "\n",
    "        Returns:\n",
    "            A request.Response object of the target request.\n",
    "        \"\"\"\n",
    "        return cls.retry(\n",
    "            requests.get,\n",
    "            logger=logger,\n",
    "            url=url,\n",
    "            params=params,\n",
    "            timeout=timeout\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def retry(cls, func, logger=None, *args, **kwargs):\n",
    "        \"\"\"A helper function to retry requests when encountering errors and exceptions.\n",
    "\n",
    "        Args:\n",
    "            func: A function of the target request.\n",
    "            logger: A logger object for logging errors and exceptions.\n",
    "            *args: A list of params for the request function.\n",
    "            **kwargs: A dictionary of params for the request function.\n",
    "\n",
    "        Returns:\n",
    "            A request.Response object of the target request.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                response = func(*args, **kwargs)\n",
    "                if response.status_code in cls.retry_c:\n",
    "                    response.raise_for_status()\n",
    "                return response\n",
    "            except cls.retry_e as e:\n",
    "                if logger:\n",
    "                    logger.info(e)\n",
    "                time.sleep(cls.retry_interval)\n",
    "                continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "title_similarity_threshold = 0.5\n",
    "\n",
    "def compare_title(query_title, resp_title, resp_subtitle):\n",
    "    \"\"\"Get the titles' text similarity by TFIDF.\n",
    "\n",
    "    Args:\n",
    "        query_title: A string of the original title.\n",
    "        resp_title: A string of the target title.\n",
    "        resp_subtitle: A string of the target subtitle.\n",
    "\n",
    "    Returns:\n",
    "         An integer of the text similarity of the titles.\n",
    "    \"\"\"\n",
    "\n",
    "    # The original title is compared with target title and target title with subtitle.\n",
    "    corpus = [query_title,\n",
    "              resp_title,\n",
    "              f\"{resp_title} {resp_subtitle}\"]\n",
    "\n",
    "    # The stop_words is disabled due to the short length of the corpus.\n",
    "    vect = TfidfVectorizer(min_df=1, stop_words=None)\n",
    "    tfidf = vect.fit_transform(corpus)\n",
    "    # The similarity is the maximum of the results.\n",
    "    similarity = max((tfidf * tfidf.T).A[0, 1:])\n",
    "    return similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def get_logger_handler(log_path=None, is_print=False, level=logging.DEBUG):\n",
    "    \"\"\"Generate the logger handlers.\n",
    "\n",
    "    Args:\n",
    "        log_path: A string of the log file path. None for no file output.\n",
    "        is_print: A boolean of whether to print the log in console.\n",
    "        level: A logging Level Object to set the logging level.\n",
    "\n",
    "    Returns:\n",
    "        A list of the logger's handlers.\n",
    "    \"\"\"\n",
    "    handlers = list()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    if is_print:\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        handler.setLevel(level)\n",
    "        handler.setFormatter(formatter)\n",
    "        handlers.append(handler)\n",
    "\n",
    "    if log_path:\n",
    "        handler = logging.FileHandler(log_path, encoding=\"utf-8\")\n",
    "        handler.setLevel(level)\n",
    "        handler.setFormatter(formatter)\n",
    "        handlers.append(handler)\n",
    "\n",
    "    return handlers\n",
    "\n",
    "time_format = time.strftime('%Y-%m-%d %H-%M-%S', time.localtime())\n",
    "log_path = \"./log\"\n",
    "os.makedirs(log_path, exist_ok=True)\n",
    "\n",
    "book_logger = logging.Logger(\"Book Scrape\", level=logging.INFO)\n",
    "book_logger.handlers = get_logger_handler(os.path.join(log_path, f\"book {time_format}.log\"))\n",
    "\n",
    "net_logger = logging.Logger(\"Connection\", level=logging.INFO)\n",
    "net_logger.handlers = get_logger_handler(os.path.join(log_path, f\"net {time_format}.log\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "\n",
    "class DebugTimer:\n",
    "    \"\"\"A simple class to record runtime of some codes.\n",
    "\n",
    "    Attributes:\n",
    "        start_time: A double of the timer's start time.\n",
    "        end_time: A double of the timer's end time.\n",
    "        desc: A string of the description of target process.\n",
    "        print_format: A string of format of print().\n",
    "        logger: A logger to output the information.\n",
    "    \"\"\"\n",
    "    start_time = 0\n",
    "    end_time = 0\n",
    "    desc = str()\n",
    "    print_format = str()\n",
    "    logger = logging.Logger(\"DebugTimer\", level=logging.INFO)\n",
    "\n",
    "    def __init__(self, desc=\"unknown process\", logger=None):\n",
    "        self.desc = desc\n",
    "        self.print_format = \"The duration of {} is: {} s.\\n\"\n",
    "        self.logger.handlers = logger.handlers if logger else get_logger_handler(is_print=True)\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.end()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\n",
    "        \"\"\"\n",
    "        self.start_time = time.perf_counter()\n",
    "\n",
    "    def end(self):\n",
    "        \"\"\"End the timer.\n",
    "        \"\"\"\n",
    "        self.end_time = time.perf_counter()\n",
    "        self.logger.info(self.print_format.format(self.desc, self.end_time - self.start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "\n",
    "\n",
    "class ScrapeBookParser:\n",
    "    \"\"\"A simple class to parse the book information from a Book Scrape page.\n",
    "\n",
    "    Attributes:\n",
    "        book_soup: A BeautifulSoup Object of the Book Scrape page.\n",
    "    \"\"\"\n",
    "    rating_str_to_num = {\n",
    "        \"one\": 1,\n",
    "        \"two\": 2,\n",
    "        \"three\": 3,\n",
    "        \"four\": 4,\n",
    "        \"five\": 5,\n",
    "    }\n",
    "\n",
    "    def __init__(self, book_soup):\n",
    "        self.book_soup = book_soup\n",
    "        self.book_main_soup = self.book_soup.find(\"div\", \"product_main\")\n",
    "        self.book_table_soup = self.book_soup.find(\"table\", \"table table-striped\")\n",
    "\n",
    "    def get_title(self):\n",
    "        return self.book_main_soup.h1.string\n",
    "\n",
    "    def get_review_num(self):\n",
    "        return int(self.book_table_soup.find(\"th\", text=\"Number of reviews\").find_next_sibling(\"td\").string)\n",
    "\n",
    "    def get_rating(self):\n",
    "        return self.rating_str_to_num[self.book_main_soup.find(\"p\", \"star-rating\")[\"class\"][1].lower()]\n",
    "\n",
    "    def get_description(self):\n",
    "        desc_soup = self.book_soup.find(\"div\", id=\"product_description\")\n",
    "        return desc_soup.find_next(\"p\").string if desc_soup else None\n",
    "\n",
    "    def get_price_excl_tax(self):\n",
    "        return self.book_table_soup.find(\"th\", text=\"Price (excl. tax)\").find_next_sibling(\"td\").string\n",
    "\n",
    "    def get_price_incl_tax(self):\n",
    "        return self.book_table_soup.find(\"th\", text=\"Price (incl. tax)\").find_next_sibling(\"td\").string\n",
    "\n",
    "    def get_product_type(self):\n",
    "        return self.book_table_soup.find(\"th\", text=\"Product Type\").find_next_sibling(\"td\").string\n",
    "\n",
    "    def get_category(self):\n",
    "        return self.book_soup.find(\"ul\", \"breadcrumb\").find(\"li\", \"active\").find_previous_sibling(\"li\").a.string\n",
    "\n",
    "    def get_availability(self):\n",
    "        return self.book_table_soup.find(\"th\", text=\"Availability\").find_next_sibling(\"td\").string\n",
    "\n",
    "class GoogleBookParser:\n",
    "    \"\"\"A simple class to parse the book information from Google Books API.\n",
    "\n",
    "    Attributes:\n",
    "        book_info: A dictionary of the book information from Google Books API.\n",
    "    \"\"\"\n",
    "    def __init__(self, book_info):\n",
    "        self.book_info = book_info\n",
    "\n",
    "    def has_title(self):\n",
    "        return \"title\" in self.book_info[\"volumeInfo\"]\n",
    "\n",
    "    def has_self_link(self):\n",
    "        return \"selfLink\" in self.book_info\n",
    "\n",
    "    def get_title(self):\n",
    "        return self.book_info[\"volumeInfo\"].get(\"title\", \"\")\n",
    "\n",
    "    def get_self_link(self):\n",
    "        return self.book_info[\"selfLink\"]\n",
    "\n",
    "    def get_subtitle(self):\n",
    "        return self.book_info[\"volumeInfo\"].get(\"subtitle\", \"\")\n",
    "\n",
    "    def get_authors(self):\n",
    "        return self.book_info[\"volumeInfo\"].get(\"authors\", [])\n",
    "\n",
    "    def get_authors_str(self, sep=\", \"):\n",
    "        return sep.join(self.get_authors())\n",
    "\n",
    "    def get_average_rating(self):\n",
    "        return self.book_info[\"volumeInfo\"].get(\"averageRating\", None)\n",
    "\n",
    "    def get_rating_count(self):\n",
    "        return self.book_info[\"volumeInfo\"].get(\"ratingsCount\", None)\n",
    "\n",
    "    def get_page_count(self):\n",
    "        return self.book_info[\"volumeInfo\"].get(\"pageCount\", None)\n",
    "\n",
    "    def get_list_price(self):\n",
    "        list_price = self.book_info.get(\"saleInfo\", dict()).get(\"listPrice\", None)\n",
    "        return f\"{list_price['amount']} {list_price['currencyCode']}\" if list_price else None\n",
    "\n",
    "    def get_retail_price(self):\n",
    "        retail_price = self.book_info.get(\"saleInfo\", dict()).get(\"retailPrice\", None)\n",
    "        return f\"{retail_price['amount']} {retail_price['currencyCode']}\" if retail_price else None\n",
    "\n",
    "def get_book_item():\n",
    "    return {\n",
    "        \"Title of Book\": ScrapeBookParser.get_title,\n",
    "        \"Number of reviews\": ScrapeBookParser.get_review_num,\n",
    "        \"Rating\": ScrapeBookParser.get_rating,\n",
    "        \"Description\": ScrapeBookParser.get_description,\n",
    "        \"Price (excl. tax)\": ScrapeBookParser.get_price_excl_tax,\n",
    "        \"Price (incl. tax)\": ScrapeBookParser.get_price_incl_tax,\n",
    "        \"Product Type\": ScrapeBookParser.get_product_type,\n",
    "        \"Book category\": ScrapeBookParser.get_category,\n",
    "        \"Availability\": ScrapeBookParser.get_availability,\n",
    "    }\n",
    "\n",
    "def get_book_extra_item():\n",
    "    return {\n",
    "        \"Google Author\": GoogleBookParser.get_authors_str,\n",
    "        \"Google Page Count\": GoogleBookParser.get_page_count,\n",
    "        \"Google Rating\": GoogleBookParser.get_average_rating,\n",
    "        \"Google Rating Count\": GoogleBookParser.get_rating_count,\n",
    "        \"Google Price\": lambda p : GoogleBookParser.get_list_price(p) or GoogleBookParser.get_retail_price(p),\n",
    "    }\n",
    "\n",
    "def get_book_list_info():\n",
    "    \"\"\"Get the main book index information.\n",
    "\n",
    "    Returns:\n",
    "        A list which contains total number, first index in one page, last index in one page (i.e. number in one page).\n",
    "    \"\"\"\n",
    "    response = CommonRequest.common_get(\"http://books.toscrape.com/index.html\", logger=net_logger)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return [int(item.string) for item in soup.find(\"form\", \"form-horizontal\", method=\"get\").find_all(\"strong\")]\n",
    "\n",
    "def get_book_url_list(page, book_queue, *args):\n",
    "    \"\"\"Get the book urls and put them into target queue for further scrapy.\n",
    "\n",
    "    Args:\n",
    "        page: A integer of the target page index.\n",
    "        book_queue: A queue.Queue Object to put the urls into.\n",
    "        *args: A list of parameters for further scrapy.\n",
    "    \"\"\"\n",
    "    response = CommonRequest.common_get(f\"http://books.toscrape.com/catalogue/page-{page}.html\", logger=net_logger)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    urls = [item.a[\"href\"] for item in soup.findAll(\"article\", \"product_pod\")]\n",
    "\n",
    "    for url in urls:\n",
    "        book_queue.put((url, *args, ))\n",
    "\n",
    "def get_book_info(url, book_info_list, pbar):\n",
    "    \"\"\"Get one book detailed information.\n",
    "\n",
    "    Args:\n",
    "        url: A string of the sub link of one book.\n",
    "        book_info_list: A list of all the books' information.\n",
    "        pbar: A tqdm.tqdm Object for the progress of book scrapy.\n",
    "    \"\"\"\n",
    "    response = CommonRequest.common_get(f\"http://books.toscrape.com/catalogue/{url}\", logger=net_logger)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    book_parser = ScrapeBookParser(soup)\n",
    "\n",
    "    book_info = [func(book_parser) for func in get_book_item().values()]\n",
    "\n",
    "    # Remove the possible Vol. info where # serves as stop mark which misleads the query.\n",
    "    # For example: I Hate Fairyland, Vol. 1: Madly Ever After (I Hate Fairyland (Compilations) #1-5)\n",
    "    query_title = re.sub(r\"\\(.*#.*\\)\", \"\", book_parser.get_title())\n",
    "    book_extra_info = get_book_extra_info(query_title)\n",
    "\n",
    "    # List append is thread-safe.\n",
    "    book_info_list.append(book_info + book_extra_info)\n",
    "    pbar.update(1)\n",
    "\n",
    "def get_book_extra_info(query_title, check_num=3):\n",
    "    \"\"\"Get one book extra information from multi-source.\n",
    "\n",
    "    Args:\n",
    "        query_title: A string of the query title to search for.\n",
    "        check_num: A integer of the number of results to check the similarity.\n",
    "\n",
    "    Returns:\n",
    "        A list of the extra information to concat with the basic one.\n",
    "    \"\"\"\n",
    "    google_url = f'https://www.googleapis.com/books/v1/volumes'\n",
    "    response = CommonRequest.common_get(\n",
    "        google_url,\n",
    "        {\n",
    "            # Note that the query title will be quoted automatically.\n",
    "            \"q\": query_title,\n",
    "            \"langRestrict\": \"en\",\n",
    "        },\n",
    "        logger=net_logger\n",
    "    )\n",
    "    google_books = json.loads(response.content)\n",
    "    google_books = google_books['items'] if 'items' in google_books.keys() else []\n",
    "\n",
    "    for book_info in google_books[:check_num]:\n",
    "        book_parser = GoogleBookParser(book_info)\n",
    "\n",
    "        # Sometimes, the query results is incomplete, which needs further request.\n",
    "        if not book_parser.has_title() and book_parser.has_self_link():\n",
    "            new_response = CommonRequest.common_get(book_parser.get_self_link(), logger=net_logger)\n",
    "            book_info = json.loads(new_response.content)\n",
    "            book_parser = GoogleBookParser(book_info)\n",
    "\n",
    "        # Neglect the book which has no title information.\n",
    "        if not book_parser.has_title():\n",
    "            continue\n",
    "\n",
    "        google_title = book_parser.get_title()\n",
    "        google_subtitle = book_parser.get_subtitle()\n",
    "\n",
    "        similarity = compare_title(query_title, google_title, google_subtitle)\n",
    "        book_logger.info(\n",
    "            f\"\\nRequest Title: {query_title}\"\n",
    "            f\"\\nResponse Title: {google_title}\"\n",
    "            f\"\\nResponse Subtitle: {google_subtitle}\"\n",
    "            f\"\\nSimilarity: {similarity}\"\n",
    "            f\"\\nRequest Url: {response.request.url}\"\n",
    "            f\"\\n\"\n",
    "        )\n",
    "\n",
    "        # If the similarity exceeds the threshold, just judge that the two books are the same one.\n",
    "        # Note that this may lead to some inaccuracy, if threshold is assigned to an unreasonable value, as it is a hyperparameter.\n",
    "        # Refer to the book log for further fine-tune.\n",
    "        if similarity > title_similarity_threshold:\n",
    "            return [func(book_parser) for func in get_book_extra_item().values()]\n",
    "\n",
    "    return [None for _ in get_book_extra_item().values()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total book number is 1000.\n",
      "2022-10-15 21:46:44,326 - DebugTimer - INFO - The duration of Getting Book List Info is: 2.8263077000010526 s.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-15 21:46:51,472 - DebugTimer - INFO - The duration of Getting Book Url List is: 7.139823500001512 s.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [09:45<00:00,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-15 21:56:29,952 - DebugTimer - INFO - The duration of Getting Book Info is: 578.4770907999991 s.\n",
      "\n",
      "2022-10-15 21:56:30,010 - DebugTimer - INFO - The duration of Writing CSV is: 0.059273400001984555 s.\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import math\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# Headers for CSV file.\n",
    "headers = list(get_book_item().keys()) + list(get_book_extra_item().keys())\n",
    "book_info_list = list()\n",
    "result_filepath = \"./Zirui_Zhou+1927924.csv\"\n",
    "\n",
    "list_queue = queue.Queue()\n",
    "book_queue = queue.Queue()\n",
    "\n",
    "with DebugTimer(\"Getting Book List Info\"):\n",
    "    total, _, step = get_book_list_info()\n",
    "    print(f\"The total book number is {total}.\")\n",
    "\n",
    "pbar = tqdm.tqdm(range(total), position=0, leave=True)\n",
    "pbar.clear()\n",
    "\n",
    "for idx in range(math.ceil(total/step)):\n",
    "    list_queue.put((idx+1, book_queue, book_info_list, pbar))\n",
    "\n",
    "with DebugTimer(\"Getting Book Url List\"):\n",
    "    for _ in range(10):\n",
    "        QueueThread(get_book_url_list, list_queue).start()\n",
    "    list_queue.join()\n",
    "\n",
    "with DebugTimer(\"Getting Book Info\"):\n",
    "    for _ in range(20):\n",
    "        QueueThread(get_book_info, book_queue).start()\n",
    "    book_queue.join()\n",
    "\n",
    "with DebugTimer(\"Writing CSV\"):\n",
    "    pandas.DataFrame(book_info_list, columns=headers).to_csv(result_filepath, sep='\\t')\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}