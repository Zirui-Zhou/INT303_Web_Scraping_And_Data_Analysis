{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import os\n",
    "import queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "class QueueThread(threading.Thread):\n",
    "    def __init__(self, func, queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.queue = queue\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                self.func(*self.queue.get_nowait())\n",
    "                self.queue.task_done()\n",
    "            except queue.Empty:\n",
    "                break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imagehash\n",
    "\n",
    "def compare_image(image1, image2, title):\n",
    "    hash0 = imagehash.average_hash(Image.open(image1))\n",
    "    hash1 = imagehash.average_hash(Image.open(image2))\n",
    "    cutoff = 10 # maximum bits that could be different between the hashes.\n",
    "\n",
    "\n",
    "    print (hash0, hash1, hash0 - hash1, title)\n",
    "    return hash0 - hash1 < cutoff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def common_get(url):\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == requests.codes.too_many_requests:\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            return response\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4343672818844282"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "def compare_title(title1, title2, subtitle2):\n",
    "    corpus = [title1,\n",
    "              title2,\n",
    "              f\"{title2} {subtitle2}\"]\n",
    "\n",
    "    vect = TfidfVectorizer(min_df=1, stop_words=None)\n",
    "    tfidf = vect.fit_transform(corpus)\n",
    "    similarity = max((tfidf * tfidf.T).A[0, 1:])\n",
    "    return similarity\n",
    "\n",
    "compare_title(\n",
    "    \"Starving Hearts (Triangular Trade Trilogy, #1)\",\n",
    "    \"Starving Hearts\",\n",
    "    \"\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import logging, sys, os, time\n",
    "\n",
    "def get_logger_handler(log_path=None, is_print=False, level=logging.DEBUG):\n",
    "    handlers = list()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    if is_print:\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        handler.setLevel(level)\n",
    "        handler.setFormatter(formatter)\n",
    "        handlers.append(handler)\n",
    "\n",
    "    if log_path:\n",
    "        handler = logging.FileHandler(log_path, encoding=\"utf-8\")\n",
    "        handler.setLevel(level)\n",
    "        handler.setFormatter(formatter)\n",
    "        handlers.append(handler)\n",
    "\n",
    "    return handlers\n",
    "\n",
    "logger = logging.Logger(\"Book Scrape\", level=logging.INFO)\n",
    "os.makedirs(\"./log\", exist_ok=True)\n",
    "logger.handlers = get_logger_handler(f\"./log/{time.strftime('%Y-%m-%d %H-%M-%S', time.localtime())}.log\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total = 200 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [11:56<?, ?it/s]\n",
      "100%|██████████| 200/200 [01:18<00:00,  7.61s/it]"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import tqdm\n",
    "import urllib\n",
    "import json\n",
    "\n",
    "headers = [\n",
    "    \"Title of Book\",\n",
    "    \"Number of reviews\",\n",
    "    \"Rating\",\n",
    "    \"Description\",\n",
    "    \"Price\",\n",
    "    \"Product Type\",\n",
    "    \"Book category\",\n",
    "    \"Availability\",\n",
    "    \"Author\"\n",
    "]\n",
    "\n",
    "book_info_list = list()\n",
    "\n",
    "response = requests.get(\"http://books.toscrape.com/index.html\")\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# total, _, step = [int(item.string) for item in soup.find(\"form\", \"form-horizontal\", method=\"get\").find_all(\"strong\")]\n",
    "\n",
    "total = 200\n",
    "step = 20\n",
    "\n",
    "print(\"total =\", total, step)\n",
    "\n",
    "pbar = tqdm.tqdm(range(total), position=0, leave=True)\n",
    "\n",
    "def get_book_list(page):\n",
    "\n",
    "    response = common_get(f\"http://books.toscrape.com/catalogue/page-{page}.html\")\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    urls = [item.a[\"href\"] for item in soup.findAll(\"article\", \"product_pod\")]\n",
    "    book_queue = queue.Queue()\n",
    "\n",
    "    for url in urls:\n",
    "        book_queue.put((url, ))\n",
    "\n",
    "    for _ in range(20):\n",
    "        QueueThread(get_title, book_queue).start()\n",
    "    book_queue.join()\n",
    "\n",
    "rating_str_to_num = {\n",
    "    \"one\": 1,\n",
    "    \"two\": 2,\n",
    "    \"three\": 3,\n",
    "    \"four\": 4,\n",
    "    \"five\": 5,\n",
    "}\n",
    "\n",
    "os.makedirs(\"./img\", exist_ok=True)\n",
    "\n",
    "def get_title(url):\n",
    "\n",
    "    response = common_get(f\"http://books.toscrape.com/catalogue/{url}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    title = soup.find(\"div\", \"product_main\").h1.string\n",
    "\n",
    "    book_info = [\n",
    "        title,\n",
    "        int(soup.find(\"table\", \"table table-striped\").find(\"th\", text=\"Number of reviews\").find_next_sibling(\"td\").string),\n",
    "        rating_str_to_num[soup.find(\"div\", \"product_main\").find(\"p\", \"star-rating\")[\"class\"][1].lower()],\n",
    "        soup.find(\"div\", id=\"product_description\").find_next(\"p\").string if soup.find(\"div\", id=\"product_description\") else None,\n",
    "        soup.find(\"table\", \"table table-striped\").find(\"th\", text=\"Price (excl. tax)\").find_next_sibling(\"td\").string,\n",
    "        soup.find(\"table\", \"table table-striped\").find(\"th\", text=\"Product Type\").find_next_sibling(\"td\").string,\n",
    "        soup.find(\"ul\", \"breadcrumb\").find(\"li\", \"active\").find_previous_sibling(\"li\").a.string,\n",
    "        soup.find(\"table\", \"table table-striped\").find(\"th\", text=\"Availability\").find_next_sibling(\"td\").string,\n",
    "    ]\n",
    "\n",
    "    image_url = f'http://books.toscrape.com/{soup.find(\"div\", \"item active\").find(\"img\")[\"src\"].replace(\"../\", \"\")}'\n",
    "    image_path = f'./img/{urllib.parse.quote(title)[:30]}{os.path.splitext(image_url)[1]}'\n",
    "\n",
    "    # urllib.request.urlretrieve(image_url, image_path)\n",
    "\n",
    "    google_url = f'https://www.googleapis.com/books/v1/volumes?q={urllib.parse.quote(title, \"/(),\")}'\n",
    "    response = common_get(google_url)\n",
    "\n",
    "    google_books = json.loads(response.content)\n",
    "\n",
    "    if 'items' in google_books.keys():\n",
    "        google_books = google_books['items']\n",
    "    else:\n",
    "        print(google_books)\n",
    "\n",
    "    author = None\n",
    "\n",
    "    for book in google_books[0:3]:\n",
    "\n",
    "        google_title = book[\"volumeInfo\"][\"title\"]\n",
    "        subtitle = book[\"volumeInfo\"][\"subtitle\"] if \"subtitle\" in book[\"volumeInfo\"] else \"\"\n",
    "\n",
    "        similarity = compare_title(title, google_title, subtitle)\n",
    "        logger.info(f'\\n{google_url}\\n{similarity}\\n{title}\\n{google_title} {subtitle}\\n')\n",
    "\n",
    "        if compare_title(title, google_title, subtitle):\n",
    "            if \"authors\" not in book[\"volumeInfo\"].keys():\n",
    "                continue\n",
    "            author = \", \".join(book[\"volumeInfo\"][\"authors\"])\n",
    "            if 'imageLinks' in book['volumeInfo'].keys():\n",
    "                cover_image_url = book['volumeInfo']['imageLinks']['thumbnail']\n",
    "                # urllib.request.urlretrieve(cover_image_url, f'./img/{urllib.parse.quote(title)[:30]}-google{os.path.splitext(image_url)[1]}')\n",
    "            break\n",
    "\n",
    "    book_info.append(author)\n",
    "\n",
    "    # List append is thread-safe.\n",
    "    book_info_list.append(book_info)\n",
    "    pbar.update(1)\n",
    "\n",
    "list_queue = queue.Queue()\n",
    "\n",
    "for idx in range(1, math.ceil(total / step) + 1):\n",
    "    list_queue.put((idx, ))\n",
    "\n",
    "for _ in range(25):\n",
    "    QueueThread(get_book_list, list_queue).start()\n",
    "list_queue.join()\n",
    "\n",
    "pandas.DataFrame(book_info_list, columns=headers).to_csv(\"./result.csv\", sep='\\t')\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}